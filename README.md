### BERT base model (uncased)
It was introduced in [this paper](https://arxiv.org/abs/1810.04805) and first released in [this repository](https://github.com/google-research/bert)

### This model is trained on [News Category Dataset](https://www.kaggle.com/datasets/rmisra/news-category-dataset).

### Labels ğŸ·ï¸
Consists of 1-4 numbers which represents class of which 

    0  world
    1  sport
    2  business
    3  tech

#### Kindly prefer pytorch [notebook](/fine_tunning_pt.ipynb) for use.

#### You can find the pretrained model [here](https://huggingface.co/omgavy/bert-classifier-tuned/tree/main).

### [ğŸ§ª Test live here ğŸ§ª](https://omgavy.vercel.app/project/#articlecategorisation)